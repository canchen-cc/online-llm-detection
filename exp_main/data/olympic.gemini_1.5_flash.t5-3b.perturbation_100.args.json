{
    "output_file": "/home/jupyter/results/olympic.gemini_1.5_flash.gemma_2b",
    "dataset": "xsum",
    "dataset_file": "/home/jupyter/data/olympic.gemini_1.5_flash",
    "pct_words_masked": 0.3,
    "mask_top_p": 0.96,
    "span_length": 2,
    "n_perturbations": 100,
    "scoring_model_name": "gemma-2b",
    "mask_filling_model_name": "t5-3b",
    "seed": 0,
    "device": "cuda",
    "cache_dir": "/home/jupyter/gcs-mount/cache",
    "hf_token": "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"
}