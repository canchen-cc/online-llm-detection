# ONLINE DETECTING LLM-GENERATED TEXTS
**This code is for ICLR 2025 paper "ONLINE DETECTING LLM-GENERATED TEXTS VIA SEQUENTIAL HYPOTHESIS TESTING BY BETTING "**, where we borrow or extend some code from [Fast-DetectGPT](https://github.com/baoguangsheng/fast-detect-gpt) and [auditing-fairness](https://github.com/ bchugg/auditing-fairness).

[Paper](url) 
| [LocalDemo](#local-demo)
| [OnlineDemo](http://region-9.autodl.pro:21504/)
| [OpenReview](https://openreview.net/forum?id=Bpcgcr8E8Z)

## Brief Info
Our method is used for detecting the source of texts observed in a streaming fashion. Tests are conducted in the black-box setting, which means the model used for scoring texts is different from the source model used to generate texts. The souce models are applied to generate equal number of fake texts based on human-written texts. There are 10 score functions: Fast-DetectGPT (sampling_discrepancy), DetectGPT (perturbation_100), LRR, NPR, Likelihood, Logrank, Entropy, DNA-GPT, RoBERTa-base, RoBERTa-large. The scoring models Neo2.7 and Gemma-2B are considered to evaluate the metrics involved in the first 8 score functions. 

## Environment
* Python3.10
* PyTorch2.4.0
* Setup the environment:
  ```bash setup.sh```
  
(Notes: our experiments are run on 1 GPU of Tesla A100 with 40G memory.)

## Workspace
Folders created for our experiments include:
* ./exp_main -> experiments for detecting Paris 2024 Olympic news or fake Olympic news which are generated by Gemini-1.5-Flash, Gemini-1.5-Pro and PaLM 2, scoring models are GPT-Neo-2.7B and Gemma-2B.
*  ./exp_gpt3to4 -> experiments for detecting human-written texts or LLM-generated texts based on the exsiting dataset of [Fast-DetectGPT] (https://github.com/baoguangsheng/fast-detect-gpt). Source models are GPT-3, ChatGPT and GPT-4, the scoring model is GPT-Neo-2.7B.
** ././raw_data -> human-written texts and the equal number of fake texts generated by 3 source models based on the first 30 tokens of human-written texts.
** ././text_score -> scores of human-written texts and LLM-generated texts.
** ././results -> raw results of detecting human-written texts and LLM-generated texts with a specific score function under each configuration, results of 10 score functions under the same configuration which are used to plot; results of plotting.


## Process
* Firslty, we let a source model generate texts based on each human-written texts.
* Then, we score human-written-texts and LLM-generated texts.
* Next, we use our algorithm to detect the source of a sequence of texts. The 
* If the source is human, we calculate the false positive rate (FPR), otherwise we report the rejection time, i.e., the time that the source is declared to be an LLM.


### Citation
If you find this work useful, you can cite it with the following BibTex entry:

   
