# ONLINE DETECTING LLM-GENERATED TEXTS
**This code is for ICLR 2025 paper "ONLINE DETECTING LLM-GENERATED TEXTS VIA SEQUENTIAL HYPOTHESIS TESTING BY BETTING "**, where we borrow or extend some code from [Fast-DetectGPT](https://github.com/baoguangsheng/fast-detect-gpt) and [auditing-fairness](https://github.com/ bchugg/auditing-fairness).

[Paper](url) 
| [LocalDemo](#local-demo)
| [OnlineDemo](http://region-9.autodl.pro:21504/)
| [OpenReview](https://openreview.net/forum?id=Bpcgcr8E8Z)

## Brief Info
Our method is used for detecting the source of texts observed in a streaming fashion. Tests are conducted in the black-box setting, which means the model used for scoring texts is different from the source model used to generate texts. The souce models are applied to generate equal number of fake texts based on human-written texts. There are 10 score functions: Fast-DetectGPT (sampling_discrepancy), DetectGPT (perturbation_100), LRR, NPR, Likelihood, Logrank, Entropy, DNA-GPT, RoBERTa-base, RoBERTa-large. The scoring models Neo2.7 and Gemma-2B are considered to evaluate the metrics involved in the first 8 score functions. 

## Environment
* Python3.10
* PyTorch2.4.0
* Setup the environment:
  ```bash setup.sh```
  
(Notes: our experiments are run on 1 GPU of Tesla A100 with 40G memory.)

## Workspace
Folders created for our experiments include:
* ./exp_main -> experiments for detecting Paris 2024 Olympic news or fake Olympic news which are generated by Gemini-1.5-Flash, Gemini-1.5-Pro and PaLM 2, scoring models are GPT-Neo-2.7B and Gemma-2B.
*  ./exp_gpt3to4 -> experiments for detecting human-written texts or LLM-generated texts based on the exsiting dataset of [Fast-DetectGPT] (https://github.com/baoguangsheng/fast-detect-gpt). Source models are GPT-3, ChatGPT and GPT-4, the scoring model is GPT-Neo-2.7B.
* ././raw_data -> human-written texts and the equal number of fake texts generated by 3 source models based on the first 30 tokens of human-written texts.
* ././text_score -> scores of human-written texts and LLM-generated texts.
* ././results -> raw results of detecting human-written texts and LLM-generated texts with a specific score function under each configuration, results of 10 score functions under the same configuration which are used to plot; results of plotting.

## Scenarios
Two scenarios are considered, including:
* Scenario 1 (oracle): with the assumption that one has prior knowledge of parameters $d_*$ and $\epsilon$. 
* Scenario 2: we specify the value of $\epsilon$ according to 20 human-written texts. The value of $d_*$ (or $d_t$) is estimated using samples collected in the first 10 times steps, and then the hypothesis testing is started thereafter.
  
## Process
* Firslty, we let a source model generate the equal number of texts based on each human-written text.
* Next, we score all the human-written-texts and LLM-generated texts.
* Then, we use our methods to detect the source of a sequence of texts.  
* For each significance level, we calculate the false positive rate (FPR) if the source is human, otherwise we report the rejection time, i.e., the time step at which the source is declared to be an LLM.


### Citation
If you find this work useful, you can cite it with the following BibTex entry:

   
